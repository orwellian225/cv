{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "\n",
    "np.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import decode_image, read_image, ImageReadMode\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "class PuzzleImages(Dataset):\n",
    "    def __init__(self, description_dir, mask_dir, img_dir, type): \n",
    "        description = pd.read_csv(description_dir)\n",
    "        self.description = description[description[\"type\"] == type].reset_index() \n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "\n",
    "        self.image_transforms = v2.Compose([\n",
    "            v2.Resize((512, 512))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.description)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, identifier, image_file, mask_file, img_type = self.description.loc[idx]\n",
    "        image = self.image_transforms(read_image(f\"{self.img_dir}/{image_file}\").float() / 255)\n",
    "        temp_mask = self.image_transforms(read_image(f\"{self.mask_dir}/{mask_file}\").float() / 255 > 0.5).float()\n",
    "\n",
    "        mask = torch.cat([temp_mask, 1 - temp_mask], dim=0)\n",
    "        return image, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PuzzleImages(\"./data.csv\", \"./masks\", \"./images\", \"train\")\n",
    "test_dataset = PuzzleImages(\"./data.csv\", \"./masks\", \"./images\", \"test\")\n",
    "val_dataset = PuzzleImages(\"./data.csv\", \"./masks\", \"./images\", \"val\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_padding = (1,1)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "transpose_size = (2,2)\n",
    "transpose_stride = (2,2)\n",
    "upsample_scale_factor = 2\n",
    "\n",
    "class UNetPoolBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_stride),\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, in_map):\n",
    "        return self.block(in_map)\n",
    "\n",
    "class UNetTransposeUpBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(in_channels=in_channel, out_channels=in_channel, kernel_size=transpose_size, stride=transpose_stride),\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, in_map):\n",
    "        return self.block(in_map)\n",
    "\n",
    "class UNetSampleUpBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=upsample_scale_factor),\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, in_map):\n",
    "        return self.block(in_map)\n",
    "\n",
    "class UNetTransposeBottleneckBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, mid_channel, out_channel, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_stride),\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=mid_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=mid_channel, out_channels=mid_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=mid_channel, kernel_size=transpose_size, stride=transpose_stride),\n",
    "            torch.nn.Conv2d(in_channels=mid_channel, out_channels=out_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, in_map):\n",
    "        return self.block(in_map)\n",
    "\n",
    "class UNetSampleBottleneckBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, mid_channel, out_channel, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_stride),\n",
    "            torch.nn.Conv2d(in_channels=in_channel, out_channels=mid_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=mid_channel, out_channels=mid_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=upsample_scale_factor),\n",
    "            torch.nn.Conv2d(in_channels=mid_channel, out_channels=out_channel, kernel_size=kernel_size, padding=kernel_padding),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, in_map):\n",
    "        return self.block(in_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetSimple(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=3, padding=(1,1)),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.first_down = UNetPoolBlock(64, 128, 3)\n",
    "        self.bottlneck = UNetSampleBottleneckBlock(128, 256, 128, 3)\n",
    "        self.first_up = UNetSampleUpBlock(128 + 128, 64, 3)\n",
    "        self.out_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64 + 64, 2, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = torch.nn.Softmax2d()\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_map = self.in_block(input)\n",
    "        down_map = self.first_down(in_map)\n",
    "        bottleneck_map = self.bottlneck(down_map)\n",
    "        up_map = self.first_up(torch.cat((down_map, bottleneck_map), dim=1))\n",
    "        out_map = self.out_block(torch.cat((in_map, up_map), dim=1))\n",
    "        return self.classifier(out_map)\n",
    "\n",
    "class UNetTranspose(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU()\n",
    "        )\n",
    "        self.first_down = UNetPoolBlock(64, 128, 3)\n",
    "        self.second_down = UNetPoolBlock(128, 256, 3)\n",
    "        self.third_down = UNetPoolBlock(256, 512, 3)\n",
    "        self.bottlneck = UNetTransposeBottleneckBlock(512, 1024, 512, kernel_size=3)\n",
    "        self.first_up = UNetTransposeUpBlock(512 + 512, 256, 3)\n",
    "        self.second_up = UNetTransposeUpBlock(256 + 256, 128, 3)\n",
    "        self.third_up = UNetTransposeUpBlock(128 + 128, 64, 3)\n",
    "        self.out_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64 + 64, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Softmax2d()\n",
    "\n",
    "    def forward(self, in_image):\n",
    "        in_map = self.in_block(in_image)\n",
    "        firstdown_map = self.first_down(in_map)\n",
    "        seconddown_map = self.second_down(firstdown_map)\n",
    "        thirddown_map = self.third_down(seconddown_map)\n",
    "        bottleneck_map = self.bottlneck(thirddown_map)\n",
    "\n",
    "        firstup_map = self.first_up(torch.cat((thirddown_map, bottleneck_map), dim=1))\n",
    "        secondup_map = self.second_up(torch.cat((seconddown_map, firstup_map), dim=1))\n",
    "        thirdup_map = self.third_up(torch.cat((firstdown_map, secondup_map), dim=1))\n",
    "        feature_map = self.out_block(torch.cat((in_map, thirdup_map), dim=1))\n",
    "\n",
    "        return self.classifer(feature_map)\n",
    "\n",
    "class UNetUpsample(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU()\n",
    "        )\n",
    "        self.first_down = UNetPoolBlock(64, 128, 3)\n",
    "        self.second_down = UNetPoolBlock(128, 256, 3)\n",
    "        self.third_down = UNetPoolBlock(256, 512, 3)\n",
    "        self.bottlneck = UNetSampleBottleneckBlock(512, 1024, 512, 3)\n",
    "        self.first_up = UNetSampleUpBlock(512 + 512, 256, 3)\n",
    "        self.second_up = UNetSampleUpBlock(256 + 256, 128, 3)\n",
    "        self.third_up = UNetSampleUpBlock(128 + 128, 64, 3)\n",
    "        self.out_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64 + 64, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, padding=(1,1)),\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 2, kernel_size=3, padding=(1,1)),\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Softmax2d()\n",
    "\n",
    "    def forward(self, in_image):\n",
    "\n",
    "        in_map = self.in_block(in_image)\n",
    "        firstdown_map = self.first_down(in_map)\n",
    "        seconddown_map = self.second_down(firstdown_map)\n",
    "        thirddown_map = self.third_down(seconddown_map)\n",
    "        bottleneck_map = self.bottlneck(thirddown_map)\n",
    "        firstup_map = self.first_up(torch.cat((thirddown_map, bottleneck_map), dim=1))\n",
    "        secondup_map = self.second_up(torch.cat((seconddown_map, firstup_map), dim=1))\n",
    "        thirdup_map = self.third_up(torch.cat((firstdown_map, secondup_map), dim=1))\n",
    "        feature_map = self.out_block(torch.cat((in_map, thirdup_map), dim=1))\n",
    "        # print(\"feature map shape:\", feature_map.shape)\n",
    "\n",
    "        return self.classifier(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "transpose_model = UNetTranspose()\n",
    "upsample_model = UNetUpsample()\n",
    "simple_model = UNetSimple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(input: torch.Tensor, target: torch.Tensor, threshold: float):\n",
    "    union = ((input > threshold) | target.bool())\n",
    "    intersection = ((input > threshold) & target.bool())\n",
    "\n",
    "    return intersection.sum() / union.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, threshold = 0.5, learning_rate=0.001):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    all_loss, layer0_loss, layer1_loss = 0, 0, 0\n",
    "    all_iou, layer0_iou, layer1_iou= 0, 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        all_loss += loss.item()\n",
    "        layer0_loss += loss_fn(pred[:,0], y[:,0]).item()\n",
    "        layer1_loss += loss_fn(pred[:,1], y[:,1]).item()\n",
    "\n",
    "        all_iou += iou(pred, y, threshold).item()\n",
    "        layer0_iou += iou(pred[:,0], y[:,0], threshold).item()\n",
    "        layer1_iou += iou(pred[:,1], y[:,1], threshold).item()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    all_loss /= num_batches\n",
    "    layer0_loss /= num_batches\n",
    "    layer1_loss /= num_batches\n",
    "\n",
    "    all_iou /= num_batches\n",
    "    layer0_iou /= num_batches\n",
    "    layer1_iou /= num_batches\n",
    "\n",
    "    return {\n",
    "        \"train/loss\": all_loss,\n",
    "        \"train/fg_loss\": layer0_loss,\n",
    "        \"train/bg_loss\": layer1_loss,\n",
    "        \"train/IoU\": all_iou,\n",
    "        \"train/fg_IoU\": layer0_iou,\n",
    "        \"train/bg_IoU\": layer1_iou,\n",
    "    }\n",
    "\n",
    "def validate(dataloader, model, threshold = 0.5):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    all_loss, layer0_loss, layer1_loss = 0, 0, 0\n",
    "    all_iou, layer0_iou, layer1_iou= 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            all_loss += loss_fn(pred, y).item()\n",
    "            layer0_loss += loss_fn(pred[:,0], y[:,0]).item()\n",
    "            layer1_loss += loss_fn(pred[:,1], y[:,1]).item()\n",
    "\n",
    "            all_iou += iou(pred, y, threshold).item()\n",
    "            layer0_iou += iou(pred[:,0], y[:,0], threshold).item()\n",
    "            layer1_iou += iou(pred[:,1], y[:,1], threshold).item()\n",
    "\n",
    "    all_loss /= num_batches\n",
    "    layer0_loss /= num_batches\n",
    "    layer1_loss /= num_batches\n",
    "\n",
    "    all_iou /= num_batches\n",
    "    layer0_iou /= num_batches\n",
    "    layer1_iou /= num_batches\n",
    "\n",
    "    return {\n",
    "        \"validate/loss\": all_loss,\n",
    "        \"validate/fg_loss\": layer0_loss,\n",
    "        \"validate/bg_loss\": layer1_loss,\n",
    "        \"validate/IoU\": all_iou,\n",
    "        \"validate/fg_IoU\": layer0_iou,\n",
    "        \"validate/bg_IoU\": layer1_iou,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_run = 0\n",
    "transpose_run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(model, num_epochs, threshold, initial_learning_rate, run_name):\n",
    "    print(f\"{run_name} for {num_epochs} epochs\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(f\"\\tThreshold = {threshold}\")\n",
    "    print(f\"\\tInitial Learning Rate = {initial_learning_rate}\")\n",
    "    wandb.init(\n",
    "        project=\"computer-vision-lab-3\",\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"architecture\": \"UNet\",\n",
    "            \"epochs\": num_epochs,\n",
    "            \"threshold\": threshold,\n",
    "            \"initial_learning_rate\": initial_learning_rate\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for t in range(num_epochs):\n",
    "        print(f\"Epoch {t + 1}\")\n",
    "        print(\"\\tTraining\")\n",
    "        train_results = train(train_dataloader, model.to(device), threshold=threshold, learning_rate=initial_learning_rate)\n",
    "        print(\"\\tValidating\")\n",
    "        val_results = validate(val_dataloader, model.to(device), threshold=threshold)\n",
    "\n",
    "        wandb.log(train_results | val_results)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pipeline(simple_model, 4, 0.5, 0.1, f\"Simple Model A - alpha = 0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsample(No ReLU) Run 1 for 3 epochs\n",
      "Hyperparameters:\n",
      "\tThreshold = 0.5\n",
      "\tInitial Learning Rate = 0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Orwellian\\University\\2024\\cv\\lab3\\wandb\\run-20240916_150352-gq4gy8op</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3/runs/gq4gy8op' target=\"_blank\">Upsample(No ReLU) Run 1</a></strong> to <a href='https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3' target=\"_blank\">https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3/runs/gq4gy8op' target=\"_blank\">https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3/runs/gq4gy8op</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\tTraining\n",
      "\tValidating\n",
      "Epoch 2\n",
      "\tTraining\n",
      "\tValidating\n",
      "Epoch 3\n",
      "\tTraining\n",
      "\tValidating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/IoU</td><td>▁██</td></tr><tr><td>train/bg_IoU</td><td>▁██</td></tr><tr><td>train/bg_loss</td><td>█▁▁</td></tr><tr><td>train/fg_IoU</td><td>█▁▁</td></tr><tr><td>train/fg_loss</td><td>█▁▁</td></tr><tr><td>train/loss</td><td>█▁▁</td></tr><tr><td>validate/IoU</td><td>▁▁█</td></tr><tr><td>validate/bg_IoU</td><td>▁▁█</td></tr><tr><td>validate/bg_loss</td><td>██▁</td></tr><tr><td>validate/fg_IoU</td><td>▁▁▁</td></tr><tr><td>validate/fg_loss</td><td>██▁</td></tr><tr><td>validate/loss</td><td>██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/IoU</td><td>0.59642</td></tr><tr><td>train/bg_IoU</td><td>0.74694</td></tr><tr><td>train/bg_loss</td><td>25.30621</td></tr><tr><td>train/fg_IoU</td><td>0</td></tr><tr><td>train/fg_loss</td><td>25.30621</td></tr><tr><td>train/loss</td><td>25.30621</td></tr><tr><td>validate/IoU</td><td>0.61761</td></tr><tr><td>validate/bg_IoU</td><td>0.76354</td></tr><tr><td>validate/bg_loss</td><td>23.64588</td></tr><tr><td>validate/fg_IoU</td><td>0</td></tr><tr><td>validate/fg_loss</td><td>23.64588</td></tr><tr><td>validate/loss</td><td>23.64588</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Upsample(No ReLU) Run 1</strong> at: <a href='https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3/runs/gq4gy8op' target=\"_blank\">https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3/runs/gq4gy8op</a><br/> View project at: <a href='https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3' target=\"_blank\">https://wandb.ai/bgriffiths-2426285-university-of-the-witwatersrand/computer-vision-lab-3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240916_150352-gq4gy8op\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_pipeline(upsample_model, 3, 0.5, 0.05, f\"Upsample(No ReLU) Run {upsample_run + 1}\")\n",
    "upsample_run += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
